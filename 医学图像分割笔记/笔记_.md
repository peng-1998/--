  
  
- [1 任务与数据集](#1-任务与数据集 )
  - [1.1 任务](#11-任务 )
  - [1.2 2D数据集](#12-2d数据集 )
  - [1.3 3D数据集](#13-3d数据集 )
- [2 方法](#2-方法 )
  - [2.1 有监督方法](#21-有监督方法 )
  - [2.2 半监督方法](#22-半监督方法 )
    - [2.3.1 对伪标签进行增强](#231-对伪标签进行增强 )
  - [2.3 无监督方法](#23-无监督方法 )
    - [2.3.1 领域自适应](#231-领域自适应 )
    - [2.3.2 基于CycleGAN的方法](#232-基于cyclegan的方法 )
- [3 模型](#3-模型 )
  - [3.1 Unet家族](#31-unet家族 )
    - [3.1.1 Unet](#311-unet )
    - [3.1.2 Encoder 和 Decoder Block 的改进](#312-encoder-和-decoder-block-的改进 )
      - [3.1.2.1 残差块](#3121-残差块 )
      - [3.1.2.2 密集理解模块](#3122-密集理解模块 )
      - [3.1.2.3 Transformer](#3123-transformer )
    - [3.1.3 连接方式的改进](#313-连接方式的改进 )
      - [3.1.3.1 增加层数的跳跃理解](#3131-增加层数的跳跃理解 )
      - [3.1.3.2 复杂链接的U-net](#3132-复杂链接的u-net )
        - [3.1.3.2.1 U-net++](#31321-u-net )
        - [3.1.3.2.2](#31322 )
    - [3.1.4 下采样与上采样的改进](#314-下采样与上采样的改进 )
    - [3.1.5 特征融合方法改进](#315-特征融合方法改进 )
  - [3.2 多分支模型](#32-多分支模型 )
    - [3.2.1 基于多模型的分支融合模型](#321-基于多模型的分支融合模型 )
  - [3.3 级联模型](#33-级联模型 )
  - [3.4 多尺度输入模型](#34-多尺度输入模型 )
  - [神经架构搜索](#神经架构搜索 )
- [4 损失函数](#4-损失函数 )
  - [4.1 交叉熵家族](#41-交叉熵家族 )
    - [4.1.1 交叉熵](#411-交叉熵 )
    - [4.1.2 TopK](#412-topk )
    - [4.1.3 Focal Loss](#413-focal-loss )
  - [4.2 Dice家族](#42-dice家族 )
    - [4.2.1 广义Dice损失](#421-广义dice损失 )
    - [4.2.2 IoU损失](#422-iou损失 )
  - [4.3 基于边界的损失](#43-基于边界的损失 )
    - [4.3.1 Hausdorff Distance (HD) loss](#431-hausdorff-distance-hd-loss )
  - [5 后处理方法](#5-后处理方法 )
  - [讨论](#讨论 )
- [5 评价标准](#5-评价标准 )
  - [5.1 基于准确率的评价指标](#51-基于准确率的评价指标 )
  - [5.2 基于距离的评价指标](#52-基于距离的评价指标 )
  
#  1 任务与数据集
  
##  1.1 任务
  
##  1.2 2D数据集
  
##  1.3 3D数据集
  
  
#  2 方法
  
##  2.1 有监督方法
  
##  2.2 半监督方法
  
###  2.3.1 对伪标签进行增强
  
##  2.3 无监督方法
  
###  2.3.1 领域自适应
  
###  2.3.2 基于CycleGAN的方法
  
#  3 模型
  
##  3.1 Unet家族
  
  
###  3.1.1 Unet
  
Unet 医学图像分割任务当中的经典模型。Unet采用下采样-跳跃链接-上采样的设计。
下采样设计能够捕获不同层次的信息，跳跃链接能够让低层次的细节信息更好的保持，而上采样过程会不断融合各个层次的信息。
可以说U-net已经不是一个特定的网络，它已经成为了医学图像分割领域的一个模型的设计范式。
  
###  3.1.2 Encoder 和 Decoder Block 的改进
  
对编码与解码模块的改进是各种改进网络的主流方式，因为原始的U-net在这方面的设计确实过于简单。
####  3.1.2.1 残差块
  
将残差网络当中的残差块应用到U-net当中是一件相当容易的事情。
####  3.1.2.2 密集理解模块
  
将具有密集链接的模块用的做Encoder和Decoder也很容易。
####  3.1.2.3 Transformer
  
随着Transformer模型在机器视觉领域的流行，有许多研究将Transformer与U-net进行结合。
有直接将卷积操作全部替换成Transformer模型的，有些将Transformer放在U-net的最后一层。
  
  
  
###  3.1.3 连接方式的改进
  
U-net当中的跳跃连接非常直观也非常简单。所以有了更加复杂的连接方式。
####  3.1.3.1 增加层数的跳跃理解
  
一些学者认为U-net当中不同层次的信息因为经过的网络层数不同，可能会导致特征融合结果不理想。
因此他们在跳跃连接的时候通过了额外的网络层，这样的网络通常是具有残差链接的网络，并且通常会使各个层次的特征经过相同数量的卷积层。
####  3.1.3.2 复杂链接的U-net
  
#####  3.1.3.2.1 U-net++
  
U-net++具有非常复杂的连接设计。
首先，在同一层上的模块使用了密集链接设计，同时还在中间层也添加了上采样连接。
<center> 
<img src="image/unet++.png" width="800px" height="500px" >
</center>
#####  3.1.3.2.2 
  
<center> 
<img src="image/3.1.3.2.2.jpg" width="800px" height="500px">
</center>
  
  
###  3.1.4 下采样与上采样的改进
  
下采样和上采样的选择都有很多种选择。下采样方式有平均池化、最大池化、步长不为1的卷积。而上采样的方式有转置卷积、插值采样、反池化等方法。
  
###  3.1.5 特征融合方法改进
  
融合方法有通常有拼接以及相加两种方式对调整图进行融合。除此之外，还有使用注意力机制对特征图进行融合的方法。
  
##  3.2 多分支模型
  
###  3.2.1 基于多模型的分支融合模型
  
##  3.3 级联模型
  
  
##  3.4 多尺度输入模型
  
多尺度输入模型是指将原始图片进行缩小然后按照尺度大小依次输入模型，通常配合金字塔模型。
使用这种方法的有PMED-net、《Region-to-boundary deep learning model with multi-scale feature fusion for medical image segmentation》
##  神经架构搜索
  
#  4 损失函数
  
##  4.1 交叉熵家族
  
###  4.1.1 交叉熵
  
图像分割问题实际上是批量的分类问题。
因此，广义的交叉熵损失可以写作：
<p align="center"><img src="https://latex.codecogs.com/gif.latex?L=%20-%20&#x5C;sum&#x5C;limits_c^C&#x5C;sum&#x5C;limits_i^N%20w_i%20q_i^c&#x5C;log%20p_i^c"/></p>  
  
###  4.1.2 TopK 
  
TopK 损失函数非常简单，在计算损失的时候保留部分较大的像素点损失值，而较小的那部分被忽略。
其可以看作是部分权重值为0的加权交叉熵损失函数。
###  4.1.3 Focal Loss
  
Focal Loss是改进的交叉熵损失：
<p align="center"><img src="https://latex.codecogs.com/gif.latex?L=%20-%20&#x5C;sum&#x5C;limits_c^C&#x5C;sum&#x5C;limits_i^N%20(1-p_i^c)^&#x5C;gamma%20q_i^c&#x5C;log%20p_i^c"/></p>  
  
其同样可以看作加权的交叉熵损失函数。
##  4.2 Dice家族
  
通常，这一类的损失函数可以写作：
<p align="center"><img src="https://latex.codecogs.com/gif.latex?L=1-2&#x5C;frac{&#x5C;sum&#x5C;limits_c^C&#x5C;sum&#x5C;limits_i^Nw_i^cp_i^cq_i^c}{&#x5C;sum&#x5C;limits_c^C&#x5C;sum&#x5C;limits_i^Nw_i^c(p_i^c+q_i^c)}"/></p>  
  
###  4.2.1 广义Dice损失
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?L=1-2&#x5C;frac{&#x5C;sum&#x5C;limits_c^Cw_c&#x5C;sum&#x5C;limits_i^Np_i^cq_i^c}{&#x5C;sum&#x5C;limits_c^Cw_c&#x5C;sum&#x5C;limits_i^N(p_i^c+q_i^c)}"/></p>  
  
当<img src="https://latex.codecogs.com/gif.latex?w_c"/>设置为1时，广义Dice损失就退化成了一般的Dice损失。
  
###  4.2.2 IoU损失
  
<p align="center"><img src="https://latex.codecogs.com/gif.latex?L=1-&#x5C;frac{&#x5C;sum&#x5C;limits_c^C&#x5C;sum&#x5C;limits_i^Np_i^cq_i^c}{&#x5C;sum&#x5C;limits_c^C&#x5C;sum&#x5C;limits_i^N(p_i^c+q_i^c-p_i^cq_i^c)}"/></p>  
  
并且，Dice损失和IoU损失具有如下关系：
<p align="center"><img src="https://latex.codecogs.com/gif.latex?L_c=&#x5C;frac{2L_d}{1+L_d}"/></p>  
  
##  4.3 基于边界的损失
  
###  4.3.1 Hausdorff Distance (HD) loss
  
  
  
##  5 后处理方法
  
  
  
##  讨论
  
对于交叉熵损失与Dice损失，可以从导数进行分析。设p是softmax输出的向量的某个值，显然<img src="https://latex.codecogs.com/gif.latex?p&#x5C;in%20(0,1)"/>。对于交叉熵损失，其参与损失函数的计算的形式为：<img src="https://latex.codecogs.com/gif.latex?C+&#x5C;frac{1}{cn}&#x5C;log%20p"/>或者是<img src="https://latex.codecogs.com/gif.latex?C+&#x5C;frac{1}{cn}&#x5C;log%20(1-p)"/>,有<img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{&#x5C;partial%20L}{&#x5C;partial%20p}=&#x5C;frac{1}{ncp}"/>或<img src="https://latex.codecogs.com/gif.latex?&#x5C;frac{&#x5C;partial%20L}{&#x5C;partial%20p}=-&#x5C;frac{1}{nc(1-p)}"/>
  
而对于Dice损失，其参与运算的形式为<img src="https://latex.codecogs.com/gif.latex?1-&#x5C;frac{2p+A}{B}"/>,其导数为<img src="https://latex.codecogs.com/gif.latex?-&#x5C;frac{2}{B}"/>。
也就是说，交叉熵损失对单个像素的惩罚会根据输出值而调整，而Dice损失对于所有对应输出的损失相同。这意味着Dice损失是一个从总体出发的惩罚，而交叉熵损失更关心单个像素是否准确。
#  5 评价标准
  
##  5.1 基于准确率的评价指标
  
##  5.2 基于距离的评价指标
  
  